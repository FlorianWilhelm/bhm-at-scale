{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import pickle\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import scipy as sp\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context(\"poster\")\n",
    "sns.set(rc={'figure.figsize': (16, 9.)})\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 120)\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)\n",
    "_logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bhm_at_scale.handler import ModelHandler\n",
    "from bhm_at_scale.model import model, guide, local_guide, check_model_guide, predictive_model, Site\n",
    "from bhm_at_scale.utils import summary, stats_to_df, preds_to_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import random, ops\n",
    "from jax import lax\n",
    "from jax import jit\n",
    "from jax.numpy import DeviceArray\n",
    "import numpy as np\n",
    "import numpyro\n",
    "from numpyro import optim\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import ELBO, SVI, Predictive\n",
    "from numpyro.infer.svi import SVIState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 942, 24)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = jnp.array(np.load('../data/preprocessed/X_train.npz')['arr_0'])\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the hierachical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model_guide(X_train, model=model, guide=guide)\n",
    "train_handler = ModelHandler(model=model, guide=guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:    0 loss:      114879.0547\n",
      "epoch: 1000 loss:        6734.7690\n",
      "epoch: 2000 loss:        6423.1729\n",
      "epoch: 3000 loss:        6406.1953\n",
      "epoch: 4000 loss:        6383.2485\n",
      "epoch: 5000 loss:        6394.3232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6371.98291015625"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_handler.fit(X_train, n_epochs=5_000, log_freq=1_000, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:    0 loss:        6371.9829\n",
      "epoch:  200 loss:        6369.5000\n",
      "epoch:  400 loss:        6368.5176\n",
      "epoch:  600 loss:        6368.0977\n",
      "epoch:  800 loss:        6370.3887\n",
      "epoch: 1000 loss:        6370.7646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6367.494140625"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_handler.fit(X_train, n_epochs=1_000, log_freq=200, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint: Save/restore current state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/result/optim_state.pickle', 'bw') as fh:\n",
    "    train_handler.dump_optim_state(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6367.4033203125"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_handler = ModelHandler(model=model, guide=guide)\n",
    "with open('../data/result/optim_state.pickle', 'br') as fh:\n",
    "     train_handler.load_optim_state(fh)\n",
    "# this is needed to initialize `svi`\n",
    "train_handler.fit(X_train, n_epochs=100, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on training set and check fitted parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_handler = ModelHandler(model=predictive_model(train_handler.model_params), guide=guide)\n",
    "pred_handler.optim_state = train_handler.optim_state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_samples = pred_handler.predict(X_train, return_sites=[Site.obs], num_samples=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_samples = train_handler.predict(X_train, return_sites=[Site.coefs, Site.coef_mus, Site.coef_sigmas], num_samples=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "for site in [Site.coef_mus, Site.coef_sigmas]:\n",
    "    samples_df = pd.DataFrame(latent_samples[site])\n",
    "    samples_df.to_csv(f'../data/result/{site}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = summary(latent_samples, poisson=True)\n",
    "df_edf = pd.read_csv('../data/preprocessed/edf.csv')\n",
    "df_stats = stats_to_df(stats, df_edf.columns[2:-1])\n",
    "df_stats.to_csv('../data/result/stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = summary(preds_samples, poisson=False)\n",
    "df_preds = preds_to_df(preds)\n",
    "df_preds.to_csv('../data/result/train_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on test set with only little data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115, 942, 24)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = jnp.array(np.load('../data/preprocessed/X_test.npz')['arr_0'])\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_days = 7  # consider only known days of history\n",
    "X_test_known = X_test[:, :known_days, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit on known data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_local_handler = ModelHandler(model=model, guide=local_guide(train_handler.model_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:    0 loss:          68.6854\n",
      "epoch:  200 loss:          49.3262\n",
      "epoch:  400 loss:          49.5047\n",
      "epoch:  600 loss:          50.0747\n",
      "epoch:  800 loss:          50.1147\n",
      "epoch: 1000 loss:          50.4854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49.72366714477539"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_local_handler.fit(X_test_known, n_epochs=1_000, log_freq=200, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:    0 loss:          49.7237\n",
      "epoch:  200 loss:          48.7054\n",
      "epoch:  400 loss:          48.2247\n",
      "epoch:  600 loss:          48.0160\n",
      "epoch:  800 loss:          48.2504\n",
      "epoch: 1000 loss:          48.5166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47.84402847290039"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_local_handler.fit(X_test_known, n_epochs=1_000, log_freq=200, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict future of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = train_handler.model_params\n",
    "params.update(train_local_handler.model_params)\n",
    "pred_local_handler = ModelHandler(model=predictive_model(params), guide=local_guide(params))\n",
    "pred_local_handler.optim_state = train_local_handler.optim_state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_samples = pred_local_handler.predict(X_test, return_sites=[Site.obs], num_samples=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = summary(preds_samples, poisson=False)\n",
    "df_preds = preds_to_df(preds).assign(StoreId=lambda df: df.StoreId + 1000)\n",
    "df_preds.to_csv('../data/result/test_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with conventional Poisson regression using Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a single store_id\n",
    "store_id = 16\n",
    "X = np.nan_to_num(X_test_known, nan=1.0)[store_id, ...]\n",
    "X, y = X[:, :-1], X[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we fit on the log-transformed target to achieve a multiplicate relationship\n",
    "reg.fit(X, np.log(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.7683716e-07, -7.8125000e-03, -4.3945312e-03,  9.7656250e-04,\n",
       "       -5.3710938e-03,  9.5367432e-07, -2.9296875e-03], dtype=float32)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# high overfit since we have more features than target values\n",
    "np.exp(reg.predict(X)) - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([5639.725  , -195.73486, -948.5249 , -158.41504,  -18.72998,\n",
       "             5615.995  ,  186.97461], dtype=float32)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no overfitting in case of the Bayesian model\n",
    "jnp.mean(preds_samples[Site.obs], axis=0)[store_id][:known_days] - y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the coefficients of conventional regression to the hierarchical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.1747565, -2.2386408,  2.144292 ,  1.9889385,  1.9385108,\n",
       "        1.8024142, -6.8102694,  1.1747564,  2.2386408, -2.2386408,\n",
       "        0.       ,  0.       , -0.0943485,  0.       ,  0.       ,\n",
       "        0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "        0.       ,  0.       ,  0.       ], dtype=float32)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for many feature there is no meaningful value, i.e. 0, since they were not encountered in training\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.7901876  2.6591206  2.688186   2.6126776  2.6567733  2.5543957\n",
      " 2.4938378  0.33227593 3.1156936  2.9264405  2.6920953  2.9548461\n",
      " 0.05613961 0.06542101 2.8379257  2.9023957  3.5701392  3.207435\n",
      " 4.056985   2.9304533  2.7463422  2.8231895  2.9590063 ]\n"
     ]
    }
   ],
   "source": [
    "# using the global prior it's possible to derive meaningful values\n",
    "coefs_samples = pred_local_handler.predict(X_test_known, return_sites=[Site.coefs], num_samples=200)\n",
    "print(jnp.mean(coefs_samples[Site.coefs], axis=0)[store_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now compare those coefficients to the ones fitted on the whole time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:     0 loss:        7813.2842\n",
      "epoch:  1000 loss:        7226.6973\n",
      "epoch:  2000 loss:        7251.3184\n",
      "epoch:  3000 loss:        7163.0728\n",
      "epoch:  4000 loss:        7166.2578\n",
      "epoch:  5000 loss:        7116.2334\n",
      "epoch:  6000 loss:        7119.3320\n",
      "epoch:  7000 loss:        7191.9634\n",
      "epoch:  8000 loss:        7127.7339\n",
      "epoch:  9000 loss:        7166.2593\n",
      "epoch: 10000 loss:        7137.1484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7158.21337890625"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_local_handler = ModelHandler(model=model, guide=local_guide(train_handler.model_params))\n",
    "all_local_handler.fit(X_test[store_id:store_id+1], n_epochs=10_000, log_freq=1_000, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.8149958   2.7551858   2.618216    2.6453686   2.6726904   2.5201018\n",
      "  2.5930352   0.22652954  3.1844485   3.1163406   2.542964    2.9477344\n",
      " -0.03218627  0.06836596  2.8726478   2.925491    3.5667892   3.2158158\n",
      "  4.0523424   2.9164746   2.7241354   2.8247733   2.9598224 ]\n"
     ]
    }
   ],
   "source": [
    "# many coefficients are really similar but mind the log-space!\n",
    "all_coefs_samples = all_local_handler.predict(X_test[store_id:store_id+1], return_sites=[Site.coefs], num_samples=200)\n",
    "print(jnp.mean(all_coefs_samples[Site.coefs], axis=0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
